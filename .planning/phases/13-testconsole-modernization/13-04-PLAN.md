# Plan 13-04: TestConsole Kafka integration tests

---
wave: 1
depends_on:
  - 13-01-PLAN.md
files_modified:
  - src/FileSimulator.TestConsole/KafkaTests.cs (new)
  - src/FileSimulator.TestConsole/Models/KafkaTestResult.cs (new)
  - src/FileSimulator.TestConsole/Program.cs
  - src/FileSimulator.TestConsole/FileSimulator.TestConsole.csproj
autonomous: true
---

## Objective

Extend TestConsole to include Kafka produce/consume tests that validate the Kafka integration added in Phase 10, using both direct Kafka access and the Control API's Kafka endpoints.

## Context

Phase 10 added Kafka integration with:
- Kafka broker accessible at NodePort 30093
- Control API endpoints:
  - GET /api/kafka/topics - list topics
  - POST /api/kafka/topics - create topic
  - DELETE /api/kafka/topics/{name} - delete topic
  - POST /api/kafka/produce - produce message
  - GET /api/kafka/consume/{topic} - consume messages
  - GET /api/kafka/consumer-groups - list consumer groups

The TestConsole should validate:
1. Kafka broker connectivity (via Confluent.Kafka)
2. Topic management via API
3. Message produce/consume cycle

## Tasks

<task id="1">
Create KafkaTestResult model class.

Create file: src/FileSimulator.TestConsole/Models/KafkaTestResult.cs

Include:
- TestName (string: e.g., "Broker Connection", "Topic Create", "Produce/Consume")
- Success (bool)
- DurationMs (long)
- Details (string) - additional info like topic name, message count
- Error (string?)
</task>

<task id="2">
Add Confluent.Kafka package to project.

Modify: src/FileSimulator.TestConsole/FileSimulator.TestConsole.csproj

Add:
```xml
<PackageReference Include="Confluent.Kafka" Version="2.12.0" />
```

This matches the version used in FileSimulator.ControlApi.
</task>

<task id="3">
Create KafkaTests class with test methods.

Create file: src/FileSimulator.TestConsole/KafkaTests.cs

Implement static class with:
- TestKafkaAsync(TestConfiguration config, string apiBaseUrl) - main entry point
- TestBrokerConnectivityAsync(string bootstrapServers) - direct Kafka connection test
- TestTopicManagementAsync(HttpClient client) - create/list/delete topic via API
- TestProduceConsumeAsync(string bootstrapServers, string topicName) - direct produce/consume
- TestApiProduceConsumeAsync(HttpClient client, string topicName) - produce/consume via API
- DisplayKafkaResults(List<KafkaTestResult> results) - render results
</task>

<task id="4">
Implement broker connectivity test.

In TestBrokerConnectivityAsync:
- Create AdminClient with bootstrap servers
- Call GetMetadata() with 10-second timeout
- Verify broker count > 0
- Log broker info: ID, host, port
- Dispose client properly
</task>

<task id="5">
Implement topic management test.

In TestTopicManagementAsync:
- Create unique topic name: "test-topic-{timestamp}"
- POST /api/kafka/topics with { "name": topicName, "partitions": 1, "replicationFactor": 1 }
- GET /api/kafka/topics and verify topic appears in list
- DELETE /api/kafka/topics/{topicName}
- GET /api/kafka/topics and verify topic is removed
</task>

<task id="6">
Implement direct produce/consume test.

In TestProduceConsumeAsync:
- Create unique topic for test
- Create producer with bootstrap servers
- Produce test message: { Key: "test-key-{timestamp}", Value: "test-value-{timestamp}" }
- Verify produce result (PersistenceStatus.Persisted)
- Create consumer with unique group ID
- Subscribe to topic and consume with 10-second timeout
- Verify message key and value match
- Dispose producer and consumer
- Clean up topic
</task>

<task id="7">
Implement API produce/consume test.

In TestApiProduceConsumeAsync:
- Create unique topic via API
- POST /api/kafka/produce with { "topic": topicName, "key": "api-key", "value": "api-value" }
- Verify 200 response
- GET /api/kafka/consume/{topicName}?count=1&timeout=10
- Verify message received matches produced message
- Clean up topic via API
</task>

<task id="8">
Handle Kafka configuration from TestConfiguration.

Extract Kafka settings from config:
- Bootstrap servers (default: file-simulator.local:30093)
- From API config, find Kafka server in servers list
- Fall back to appsettings.json if available

Add to appsettings.json:
```json
"Kafka": {
  "BootstrapServers": "file-simulator.local:30093"
}
```
</task>

<task id="9">
Update Program.cs to include Kafka tests.

Modify: src/FileSimulator.TestConsole/Program.cs

Add:
- Command-line flag --kafka to run Kafka tests
- Command-line flag --skip-kafka to skip Kafka tests when running all
- Call KafkaTests.TestKafkaAsync() when flag present
- Include Kafka in default test suite (can be skipped)
</task>

<task id="10">
Implement comprehensive results display.

In DisplayKafkaResults:
- Use Spectre.Console table: Test, Status, Duration, Details
- Color-code: green for pass, red for fail
- Tests:
  - Broker Connection
  - Topic Create
  - Topic List
  - Topic Delete
  - Direct Produce
  - Direct Consume
  - API Produce
  - API Consume
- Summary: X/Y tests passed
</task>

<task id="11">
Add cleanup-on-failure handling.

Ensure test topics are deleted even if tests fail:
- Track created topics
- Use try/finally to clean up
- Log warning if cleanup fails (don't fail test for cleanup issues)
</task>

## Verification

```powershell
# Build TestConsole
cd C:\Users\UserC\source\repos\file-simulator-suite\src\FileSimulator.TestConsole
dotnet build

# Run Kafka tests (requires Kafka and Control API running)
dotnet run -- --kafka

# Run all tests including Kafka
dotnet run

# Run all tests except Kafka
dotnet run -- --skip-kafka

# Expected output:
# - Broker Connection: PASS (broker count, version)
# - Topic management: Create/List/Delete all PASS
# - Direct produce/consume: PASS with message verification
# - API produce/consume: PASS with message verification
# - Summary: 8/8 tests passed

# Verify no leftover topics
# (Topic cleanup should remove test-topic-* entries)
```

## must_haves

These criteria must be TRUE for the plan to be considered complete:

1. TestConsole can connect to Kafka broker and retrieve metadata
2. TestConsole can create, list, and delete topics via Control API
3. TestConsole can produce and consume messages directly via Confluent.Kafka
4. TestConsole can produce and consume messages via Control API endpoints
5. Test topics are cleaned up after tests complete
6. --kafka flag runs Kafka tests, --skip-kafka excludes them
7. Results displayed with timing and pass/fail status for each test
