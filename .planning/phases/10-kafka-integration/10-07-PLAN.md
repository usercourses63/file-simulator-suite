---
phase: 10-kafka-integration
plan: 07
type: execute
wave: 4
depends_on: ["10-01", "10-03", "10-06"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "Kafka broker pod is running with ZooKeeper sidecar"
    - "Default topics exist (test-events, test-commands, test-notifications)"
    - "Kafka-UI is accessible and shows cluster"
    - "Dashboard Kafka tab shows topics and allows operations"
    - "User can produce and consume messages through dashboard"
    - "Consumer group monitoring displays lag with color coding"
    - "Existing v1.0 servers remain responsive"
---

<objective>
Human verification of complete Kafka integration

Purpose: Validate that Kafka infrastructure, backend API, and dashboard UI work correctly end-to-end
Output: Verified working Kafka simulator with all success criteria confirmed
</objective>

<execution_context>
@C:\Users\UserC\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\UserC\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-kafka-integration/10-CONTEXT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build and deploy Kafka infrastructure</name>
  <files></files>
  <action>
**IMPORTANT: Before deployment, increase Minikube memory to 12GB as noted in STATE.md**

1. Increase Minikube memory (if not already done):
```bash
minikube stop -p file-simulator
minikube config set memory 12288 -p file-simulator
minikube start -p file-simulator
```

2. Build Control API with Kafka support:
```bash
cd src/FileSimulator.ControlApi
dotnet build
docker build -t file-simulator-control-api:latest .
minikube image load file-simulator-control-api:latest -p file-simulator
```

3. Build dashboard:
```bash
cd src/dashboard
npm install
npm run build
```

4. Deploy with Helm (ALWAYS use --kube-context):
```bash
helm upgrade --install file-sim ./helm-chart/file-simulator \
    --kube-context=file-simulator \
    --namespace file-simulator
```

5. Wait for Kafka pod to be ready:
```bash
kubectl --context=file-simulator wait --for=condition=ready pod \
    -l app.kubernetes.io/component=kafka \
    -n file-simulator \
    --timeout=120s
```

6. Verify all pods running:
```bash
kubectl --context=file-simulator get pods -n file-simulator
```

Expected: All pods in Running state including kafka and kafka-ui
  </action>
  <verify>
`kubectl --context=file-simulator get pods -n file-simulator` shows kafka pod Ready 2/2 (ZooKeeper + Kafka containers)
  </verify>
  <done>
Kafka infrastructure deployed and all pods running
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify default topics created</name>
  <files></files>
  <action>
Check that init job created default topics:

```bash
# Check init job completed
kubectl --context=file-simulator get jobs -n file-simulator

# Exec into Kafka pod and list topics
kubectl --context=file-simulator exec -it \
    $(kubectl --context=file-simulator get pod -l app.kubernetes.io/component=kafka -n file-simulator -o jsonpath='{.items[0].metadata.name}') \
    -n file-simulator \
    -c kafka \
    -- kafka-topics.sh --bootstrap-server localhost:9092 --list
```

Expected topics:
- test-events (3 partitions)
- test-commands (1 partition)
- test-notifications (1 partition)
  </action>
  <verify>
kafka-topics.sh --list shows test-events, test-commands, test-notifications
  </verify>
  <done>
Default topics created with correct partition counts
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Kafka integration:
- Kafka broker with ZooKeeper sidecar in same pod
- Kafka-UI management interface
- Backend API with topic management, message production/consumption, consumer group monitoring
- Dashboard Kafka tab with topic list, message producer, message viewer, consumer group detail
  </what-built>
  <how-to-verify>

**1. Verify Kafka-UI accessible:**
- Open browser to http://{MINIKUBE_IP}:30093
- Expected: Kafka-UI showing "file-simulator" cluster
- Verify: Topics tab shows test-events, test-commands, test-notifications

**2. Verify Dashboard Kafka tab:**
- Open browser to http://{MINIKUBE_IP}:30500 (or wherever dashboard is served)
- Click "Kafka" tab in navigation
- Expected: Health indicator shows "Connected" (green)
- Expected: Topics list shows 3 default topics
- Expected: Consumer Groups section (may be empty initially)

**3. Test topic creation:**
- Click "+ Create Topic" button
- Enter name: "my-test-topic"
- Enter partitions: 2
- Click "Create Topic"
- Expected: Topic appears in list with "2 partitions"

**4. Test message production:**
- Select "my-test-topic" from list
- In "Produce Message" form:
  - Key: "test-key-1"
  - Message Body: "Hello Kafka from dashboard!"
- Click "Send Message"
- Expected: Success message showing partition and offset

**5. Test message consumption:**
- Click "Consume" toggle (next to "Produce")
- Expected: Message viewer appears
- Click "Manual" mode and "Refresh"
- Expected: Your message appears with key, value, timestamp
- Click "Live" mode
- Send another message from Produce view
- Expected: New message appears automatically in Live view

**6. Test consumer group monitoring:**
- Create a consumer group by running a test consumer (or let the dashboard viewer create one)
- Expected: Consumer group appears in right panel
- Click to expand group
- Expected: Partition offsets table shows topic, partition, offset, high watermark, lag
- Expected: Lag is color-coded (green for 0-10)

**7. Test topic deletion:**
- Select "my-test-topic"
- Click delete button (x)
- Confirm deletion
- Expected: Topic removed from list

**8. Verify v1.0 servers still responsive:**
- Switch to "Servers" tab
- Expected: All 13 servers (7 NAS + 6 protocols) show healthy status
- Verify: No degradation in existing functionality

  </how-to-verify>
  <resume-signal>
Type "approved" if all checks pass, or describe any issues encountered.
  </resume-signal>
</task>

</tasks>

<verification>
Phase 10 success criteria (from ROADMAP.md):
1. [x] Single-broker Kafka cluster deploys successfully (ZooKeeper mode per user choice)
2. [ ] User can create topics through UI with specified partition count
3. [ ] User can produce test messages to topics via dashboard
4. [ ] User can consume messages from topics and view message content in UI
5. [ ] Consumer group monitoring shows offset lag and active members
6. [ ] Kafka broker health check shows green status and existing v1.0 servers remain responsive
</verification>

<success_criteria>
All items verified by human tester:
- Kafka-UI accessible at :30093
- Dashboard Kafka tab functional
- Topic CRUD operations work
- Message produce/consume works
- Consumer group detail with lag coloring works
- v1.0 servers unaffected
</success_criteria>

<output>
After completion, create `.planning/phases/10-kafka-integration/10-07-SUMMARY.md`
</output>
