---
phase: 10-kafka-integration
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - src/FileSimulator.ControlApi/FileSimulator.ControlApi.csproj
  - src/FileSimulator.ControlApi/Models/KafkaModels.cs
  - src/FileSimulator.ControlApi/Services/IKafkaAdminService.cs
  - src/FileSimulator.ControlApi/Services/KafkaAdminService.cs
  - src/FileSimulator.ControlApi/Services/IKafkaProducerService.cs
  - src/FileSimulator.ControlApi/Services/KafkaProducerService.cs
autonomous: true

must_haves:
  truths:
    - "Backend can connect to Kafka broker"
    - "Backend can list topics with partition counts"
    - "Backend can create and delete topics"
    - "Backend can produce messages to topics"
    - "Backend can list consumer groups with member counts"
  artifacts:
    - path: "src/FileSimulator.ControlApi/Services/KafkaAdminService.cs"
      provides: "Topic and consumer group management"
      contains: "AdminClientBuilder"
    - path: "src/FileSimulator.ControlApi/Services/KafkaProducerService.cs"
      provides: "Message production"
      contains: "ProducerBuilder"
    - path: "src/FileSimulator.ControlApi/Models/KafkaModels.cs"
      provides: "DTOs for Kafka operations"
      contains: "TopicInfo"
  key_links:
    - from: "KafkaAdminService.cs"
      to: "Kafka broker"
      via: "BootstrapServers configuration"
      pattern: "BootstrapServers"
    - from: "KafkaProducerService.cs"
      to: "Kafka broker"
      via: "ProducerConfig"
      pattern: "ProducerConfig"
---

<objective>
Implement Kafka backend services for topic management and message production

Purpose: Provide .NET services that interact with Kafka broker via Confluent.Kafka library
Output: KafkaAdminService (topic/group management) and KafkaProducerService (message production)
</objective>

<execution_context>
@C:\Users\UserC\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\UserC\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-kafka-integration/10-CONTEXT.md
@.planning/phases/10-kafka-integration/10-RESEARCH.md
@src/FileSimulator.ControlApi/Services/MetricsService.cs
@src/FileSimulator.ControlApi/Program.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Confluent.Kafka NuGet package and create models</name>
  <files>
src/FileSimulator.ControlApi/FileSimulator.ControlApi.csproj
src/FileSimulator.ControlApi/Models/KafkaModels.cs
  </files>
  <action>
**Add NuGet package:**
```bash
cd src/FileSimulator.ControlApi && dotnet add package Confluent.Kafka --version 2.12.0
```

**Create Models/KafkaModels.cs:**

```csharp
namespace FileSimulator.ControlApi.Models;

/// <summary>Kafka configuration options</summary>
public class KafkaOptions
{
    public string BootstrapServers { get; set; } = "kafka:9092";
}

/// <summary>Topic information</summary>
public record TopicInfo(
    string Name,
    int PartitionCount,
    int ReplicationFactor,
    long MessageCount,
    DateTime? LastActivity);

/// <summary>Topic creation request</summary>
public record CreateTopicRequest(
    string Name,
    int Partitions = 1,
    short ReplicationFactor = 1);

/// <summary>Consumer group information</summary>
public record ConsumerGroupInfo(
    string GroupId,
    string State,
    int MemberCount,
    long TotalLag);

/// <summary>Consumer group detail with partition info</summary>
public record ConsumerGroupDetail(
    string GroupId,
    string State,
    int MemberCount,
    long TotalLag,
    IReadOnlyList<ConsumerGroupMember> Members,
    IReadOnlyList<PartitionOffset> Partitions);

/// <summary>Consumer group member</summary>
public record ConsumerGroupMember(
    string MemberId,
    string ClientId,
    string Host);

/// <summary>Partition offset information</summary>
public record PartitionOffset(
    string Topic,
    int Partition,
    long CurrentOffset,
    long HighWatermark,
    long Lag);

/// <summary>Message to produce</summary>
public record ProduceMessageRequest(
    string Topic,
    string? Key,
    string Value);

/// <summary>Produced message result</summary>
public record ProduceMessageResult(
    string Topic,
    int Partition,
    long Offset,
    DateTime Timestamp);

/// <summary>Kafka message for display</summary>
public record KafkaMessage(
    string Topic,
    int Partition,
    long Offset,
    string? Key,
    string Value,
    DateTime Timestamp);

/// <summary>Offset reset request</summary>
public record ResetOffsetsRequest(
    string GroupId,
    string Topic,
    string ResetTo);  // "earliest" or "latest"
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds without errors
  </verify>
  <done>
Confluent.Kafka package added, all DTO models compile successfully
  </done>
</task>

<task type="auto">
  <name>Task 2: Create KafkaAdminService for topic and consumer group management</name>
  <files>
src/FileSimulator.ControlApi/Services/IKafkaAdminService.cs
src/FileSimulator.ControlApi/Services/KafkaAdminService.cs
  </files>
  <action>
**Create IKafkaAdminService.cs:**

```csharp
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public interface IKafkaAdminService : IDisposable
{
    Task<IReadOnlyList<TopicInfo>> GetTopicsAsync(CancellationToken ct);
    Task<TopicInfo?> GetTopicAsync(string name, CancellationToken ct);
    Task CreateTopicAsync(CreateTopicRequest request, CancellationToken ct);
    Task DeleteTopicAsync(string name, CancellationToken ct);
    Task<IReadOnlyList<ConsumerGroupInfo>> GetConsumerGroupsAsync(CancellationToken ct);
    Task<ConsumerGroupDetail?> GetConsumerGroupDetailAsync(string groupId, CancellationToken ct);
    Task ResetOffsetsAsync(ResetOffsetsRequest request, CancellationToken ct);
    Task DeleteConsumerGroupAsync(string groupId, CancellationToken ct);
    Task<bool> HealthCheckAsync(CancellationToken ct);
}
```

**Create KafkaAdminService.cs:**

Implement using Confluent.Kafka AdminClient:

```csharp
using Confluent.Kafka;
using Confluent.Kafka.Admin;
using Microsoft.Extensions.Options;
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public class KafkaAdminService : IKafkaAdminService
{
    private readonly IAdminClient _adminClient;
    private readonly ILogger<KafkaAdminService> _logger;
    private readonly string _bootstrapServers;

    public KafkaAdminService(IOptions<KafkaOptions> options, ILogger<KafkaAdminService> logger)
    {
        _logger = logger;
        _bootstrapServers = options.Value.BootstrapServers;
        _adminClient = new AdminClientBuilder(new AdminClientConfig
        {
            BootstrapServers = _bootstrapServers
        }).Build();

        _logger.LogInformation("KafkaAdminService initialized with bootstrap servers: {Servers}", _bootstrapServers);
    }

    public async Task<IReadOnlyList<TopicInfo>> GetTopicsAsync(CancellationToken ct)
    {
        var metadata = _adminClient.GetMetadata(TimeSpan.FromSeconds(10));
        var topics = metadata.Topics
            .Where(t => !t.Topic.StartsWith("__"))  // Exclude internal topics
            .Select(t => new TopicInfo(
                t.Topic,
                t.Partitions.Count,
                t.Partitions.FirstOrDefault()?.Replicas.Length ?? 1,
                0,  // Message count calculated separately if needed
                null))
            .ToList();

        _logger.LogDebug("Retrieved {Count} topics", topics.Count);
        return topics;
    }

    public async Task<TopicInfo?> GetTopicAsync(string name, CancellationToken ct)
    {
        var topics = await GetTopicsAsync(ct);
        return topics.FirstOrDefault(t => t.Name == name);
    }

    public async Task CreateTopicAsync(CreateTopicRequest request, CancellationToken ct)
    {
        var spec = new TopicSpecification
        {
            Name = request.Name,
            NumPartitions = request.Partitions,
            ReplicationFactor = request.ReplicationFactor
        };

        await _adminClient.CreateTopicsAsync(new[] { spec });
        _logger.LogInformation("Created topic {Name} with {Partitions} partitions", request.Name, request.Partitions);
    }

    public async Task DeleteTopicAsync(string name, CancellationToken ct)
    {
        await _adminClient.DeleteTopicsAsync(new[] { name });
        _logger.LogInformation("Deleted topic {Name}", name);
    }

    public async Task<IReadOnlyList<ConsumerGroupInfo>> GetConsumerGroupsAsync(CancellationToken ct)
    {
        var groups = await _adminClient.ListConsumerGroupsAsync();
        var groupInfos = new List<ConsumerGroupInfo>();

        foreach (var group in groups.Valid)
        {
            try
            {
                var descriptions = await _adminClient.DescribeConsumerGroupsAsync(
                    new[] { group.GroupId });
                var desc = descriptions.ConsumerGroupDescriptions.FirstOrDefault();

                if (desc != null)
                {
                    // Calculate total lag would require topic offsets - simplified for now
                    groupInfos.Add(new ConsumerGroupInfo(
                        desc.GroupId,
                        desc.State.ToString(),
                        desc.Members.Count,
                        0));  // Lag calculated in detail view
                }
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "Failed to describe group {GroupId}", group.GroupId);
            }
        }

        return groupInfos;
    }

    public async Task<ConsumerGroupDetail?> GetConsumerGroupDetailAsync(string groupId, CancellationToken ct)
    {
        var descriptions = await _adminClient.DescribeConsumerGroupsAsync(new[] { groupId });
        var desc = descriptions.ConsumerGroupDescriptions.FirstOrDefault();

        if (desc == null) return null;

        var members = desc.Members.Select(m => new ConsumerGroupMember(
            m.MemberId,
            m.ClientId,
            m.Host)).ToList();

        // Get committed offsets and calculate lag
        var partitions = new List<PartitionOffset>();
        try
        {
            var offsets = await _adminClient.ListConsumerGroupOffsetsAsync(
                new[] { new ConsumerGroupTopicPartitions(groupId, null) });

            foreach (var tpo in offsets.SelectMany(o => o.Partitions))
            {
                var watermark = GetWatermarkOffsets(tpo.Topic, tpo.Partition.Value);
                var lag = watermark.high - tpo.Offset.Value;

                partitions.Add(new PartitionOffset(
                    tpo.Topic,
                    tpo.Partition.Value,
                    tpo.Offset.Value,
                    watermark.high,
                    Math.Max(0, lag)));
            }
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Failed to get offsets for group {GroupId}", groupId);
        }

        var totalLag = partitions.Sum(p => p.Lag);

        return new ConsumerGroupDetail(
            desc.GroupId,
            desc.State.ToString(),
            desc.Members.Count,
            totalLag,
            members,
            partitions);
    }

    private (long low, long high) GetWatermarkOffsets(string topic, int partition)
    {
        using var consumer = new ConsumerBuilder<Ignore, Ignore>(new ConsumerConfig
        {
            BootstrapServers = _bootstrapServers,
            GroupId = $"watermark-query-{Guid.NewGuid()}"
        }).Build();

        var watermark = consumer.QueryWatermarkOffsets(
            new TopicPartition(topic, partition),
            TimeSpan.FromSeconds(5));

        return (watermark.Low.Value, watermark.High.Value);
    }

    public async Task ResetOffsetsAsync(ResetOffsetsRequest request, CancellationToken ct)
    {
        // First check if group is empty (required for offset reset)
        var detail = await GetConsumerGroupDetailAsync(request.GroupId, ct);
        if (detail == null)
            throw new InvalidOperationException($"Consumer group '{request.GroupId}' not found");

        if (detail.State != "Empty")
            throw new InvalidOperationException($"Consumer group must be inactive to reset offsets. Current state: {detail.State}");

        var targetOffset = request.ResetTo.ToLower() == "earliest"
            ? Offset.Beginning
            : Offset.End;

        // Get all partitions for the topic
        var metadata = _adminClient.GetMetadata(request.Topic, TimeSpan.FromSeconds(5));
        var topicMeta = metadata.Topics.FirstOrDefault(t => t.Topic == request.Topic);

        if (topicMeta == null)
            throw new InvalidOperationException($"Topic '{request.Topic}' not found");

        var offsets = topicMeta.Partitions.Select(p =>
            new TopicPartitionOffset(request.Topic, p.PartitionId, targetOffset)).ToList();

        await _adminClient.AlterConsumerGroupOffsetsAsync(
            new[] { new ConsumerGroupTopicPartitionOffsets(request.GroupId, offsets) });

        _logger.LogInformation("Reset offsets for group {GroupId} on topic {Topic} to {Target}",
            request.GroupId, request.Topic, request.ResetTo);
    }

    public async Task DeleteConsumerGroupAsync(string groupId, CancellationToken ct)
    {
        await _adminClient.DeleteGroupsAsync(new[] { groupId });
        _logger.LogInformation("Deleted consumer group {GroupId}", groupId);
    }

    public async Task<bool> HealthCheckAsync(CancellationToken ct)
    {
        try
        {
            var metadata = _adminClient.GetMetadata(TimeSpan.FromSeconds(5));
            return metadata.Brokers.Count > 0;
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Kafka health check failed");
            return false;
        }
    }

    public void Dispose()
    {
        _adminClient?.Dispose();
    }
}
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds without errors
  </verify>
  <done>
KafkaAdminService implements topic CRUD, consumer group listing/detail, offset reset, and health check
  </done>
</task>

<task type="auto">
  <name>Task 3: Create KafkaProducerService for message production</name>
  <files>
src/FileSimulator.ControlApi/Services/IKafkaProducerService.cs
src/FileSimulator.ControlApi/Services/KafkaProducerService.cs
  </files>
  <action>
**Create IKafkaProducerService.cs:**

```csharp
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public interface IKafkaProducerService : IDisposable
{
    Task<ProduceMessageResult> ProduceAsync(ProduceMessageRequest request, CancellationToken ct);
}
```

**Create KafkaProducerService.cs:**

```csharp
using Confluent.Kafka;
using Microsoft.Extensions.Options;
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public class KafkaProducerService : IKafkaProducerService
{
    private readonly IProducer<string, string> _producer;
    private readonly ILogger<KafkaProducerService> _logger;

    public KafkaProducerService(IOptions<KafkaOptions> options, ILogger<KafkaProducerService> logger)
    {
        _logger = logger;

        var config = new ProducerConfig
        {
            BootstrapServers = options.Value.BootstrapServers,
            Acks = Acks.All,  // Wait for all replicas
            EnableIdempotence = true  // Exactly-once semantics
        };

        _producer = new ProducerBuilder<string, string>(config).Build();
        _logger.LogInformation("KafkaProducerService initialized");
    }

    public async Task<ProduceMessageResult> ProduceAsync(ProduceMessageRequest request, CancellationToken ct)
    {
        var message = new Message<string, string>
        {
            Key = request.Key,
            Value = request.Value
        };

        var result = await _producer.ProduceAsync(request.Topic, message, ct);

        _logger.LogDebug("Produced message to {Topic}:{Partition}@{Offset}",
            result.Topic, result.Partition.Value, result.Offset.Value);

        return new ProduceMessageResult(
            result.Topic,
            result.Partition.Value,
            result.Offset.Value,
            result.Timestamp.UtcDateTime);
    }

    public void Dispose()
    {
        _producer?.Dispose();
    }
}
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds without errors
  </verify>
  <done>
KafkaProducerService can produce messages with optional keys to any topic
  </done>
</task>

</tasks>

<verification>
1. `dotnet build src/FileSimulator.ControlApi` - builds without errors
2. NuGet package Confluent.Kafka 2.12.0 present in csproj
3. All model records have correct properties
4. KafkaAdminService implements all interface methods
5. KafkaProducerService implements ProduceAsync
</verification>

<success_criteria>
- Confluent.Kafka 2.12.0 added to project
- All Kafka DTOs defined with correct structure
- KafkaAdminService handles topic CRUD and consumer group operations
- KafkaProducerService handles message production
- All services follow existing codebase patterns (IOptions, ILogger)
</success_criteria>

<output>
After completion, create `.planning/phases/10-kafka-integration/10-02-SUMMARY.md`
</output>
