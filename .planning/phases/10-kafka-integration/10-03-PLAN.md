---
phase: 10-kafka-integration
plan: 03
type: execute
wave: 2
depends_on: ["10-02"]
files_modified:
  - src/FileSimulator.ControlApi/Services/KafkaConsumerService.cs
  - src/FileSimulator.ControlApi/Controllers/KafkaController.cs
  - src/FileSimulator.ControlApi/Hubs/KafkaHub.cs
  - src/FileSimulator.ControlApi/Program.cs
autonomous: true

must_haves:
  truths:
    - "REST API endpoints return topic list"
    - "REST API can create and delete topics"
    - "REST API can produce messages"
    - "REST API returns consumer group information"
    - "SignalR hub broadcasts messages to subscribers"
  artifacts:
    - path: "src/FileSimulator.ControlApi/Controllers/KafkaController.cs"
      provides: "REST API for Kafka operations"
      contains: "[ApiController]"
    - path: "src/FileSimulator.ControlApi/Hubs/KafkaHub.cs"
      provides: "SignalR hub for real-time message streaming"
      contains: "Hub"
    - path: "src/FileSimulator.ControlApi/Services/KafkaConsumerService.cs"
      provides: "Message consumption for live feed"
      contains: "ConsumerBuilder"
  key_links:
    - from: "KafkaController.cs"
      to: "KafkaAdminService"
      via: "DI injection"
      pattern: "IKafkaAdminService"
    - from: "KafkaHub.cs"
      to: "KafkaConsumerService"
      via: "DI injection"
      pattern: "IKafkaConsumerService"
    - from: "Program.cs"
      to: "KafkaHub"
      via: "MapHub"
      pattern: "MapHub<KafkaHub>"
---

<objective>
Wire up Kafka REST API endpoints and SignalR hub for real-time message streaming

Purpose: Expose Kafka operations through HTTP API and enable real-time message feed via WebSocket
Output: KafkaController with full API, KafkaHub for live streaming, services registered in DI
</objective>

<execution_context>
@C:\Users\UserC\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\UserC\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-kafka-integration/10-CONTEXT.md
@.planning/phases/10-kafka-integration/10-RESEARCH.md
@src/FileSimulator.ControlApi/Controllers/MetricsController.cs
@src/FileSimulator.ControlApi/Hubs/MetricsHub.cs
@src/FileSimulator.ControlApi/Program.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create KafkaConsumerService for reading messages</name>
  <files>
src/FileSimulator.ControlApi/Services/IKafkaConsumerService.cs
src/FileSimulator.ControlApi/Services/KafkaConsumerService.cs
  </files>
  <action>
**Create IKafkaConsumerService.cs:**

```csharp
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public interface IKafkaConsumerService
{
    /// <summary>Get last N messages from a topic (for initial load)</summary>
    Task<IReadOnlyList<KafkaMessage>> GetRecentMessagesAsync(string topic, int count, CancellationToken ct);

    /// <summary>Start streaming messages from a topic (for live feed)</summary>
    IAsyncEnumerable<KafkaMessage> StreamMessagesAsync(string topic, CancellationToken ct);
}
```

**Create KafkaConsumerService.cs:**

```csharp
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Microsoft.Extensions.Options;
using FileSimulator.ControlApi.Models;

namespace FileSimulator.ControlApi.Services;

public class KafkaConsumerService : IKafkaConsumerService
{
    private readonly string _bootstrapServers;
    private readonly ILogger<KafkaConsumerService> _logger;

    public KafkaConsumerService(IOptions<KafkaOptions> options, ILogger<KafkaConsumerService> logger)
    {
        _bootstrapServers = options.Value.BootstrapServers;
        _logger = logger;
    }

    public async Task<IReadOnlyList<KafkaMessage>> GetRecentMessagesAsync(string topic, int count, CancellationToken ct)
    {
        var messages = new List<KafkaMessage>();
        var config = new ConsumerConfig
        {
            BootstrapServers = _bootstrapServers,
            GroupId = $"dashboard-viewer-{Guid.NewGuid()}",
            AutoOffsetReset = AutoOffsetReset.Latest,
            EnableAutoCommit = false
        };

        using var consumer = new ConsumerBuilder<string, string>(config)
            .SetValueDeserializer(Deserializers.Utf8)
            .SetKeyDeserializer(Deserializers.Utf8)
            .Build();

        // Get partitions for topic
        var metadata = consumer.GetWatermarkOffsets(
            new TopicPartition(topic, 0), TimeSpan.FromSeconds(5));

        // Query all partitions
        using var adminConsumer = new ConsumerBuilder<string, string>(config).Build();
        var topicMetadata = GetTopicPartitions(topic);

        foreach (var partition in topicMetadata)
        {
            try
            {
                var tp = new TopicPartition(topic, partition);
                var watermark = consumer.QueryWatermarkOffsets(tp, TimeSpan.FromSeconds(5));

                // Calculate start offset (N messages before high watermark)
                var startOffset = Math.Max(watermark.Low.Value, watermark.High.Value - count);
                consumer.Assign(new TopicPartitionOffset(tp, startOffset));

                // Consume messages until high watermark
                while (true)
                {
                    var result = consumer.Consume(TimeSpan.FromMilliseconds(100));
                    if (result == null) break;
                    if (result.Offset.Value >= watermark.High.Value) break;

                    messages.Add(new KafkaMessage(
                        result.Topic,
                        result.Partition.Value,
                        result.Offset.Value,
                        result.Message.Key,
                        result.Message.Value,
                        result.Message.Timestamp.UtcDateTime));

                    if (messages.Count >= count) break;
                }
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "Failed to read from partition {Partition}", partition);
            }
        }

        // Sort by timestamp descending and take requested count
        return messages
            .OrderByDescending(m => m.Timestamp)
            .Take(count)
            .ToList();
    }

    public async IAsyncEnumerable<KafkaMessage> StreamMessagesAsync(
        string topic,
        [EnumeratorCancellation] CancellationToken ct)
    {
        var config = new ConsumerConfig
        {
            BootstrapServers = _bootstrapServers,
            GroupId = $"dashboard-stream-{Guid.NewGuid()}",
            AutoOffsetReset = AutoOffsetReset.Latest,
            EnableAutoCommit = false
        };

        using var consumer = new ConsumerBuilder<string, string>(config)
            .SetValueDeserializer(Deserializers.Utf8)
            .SetKeyDeserializer(Deserializers.Utf8)
            .Build();

        consumer.Subscribe(topic);
        _logger.LogInformation("Started streaming messages from topic {Topic}", topic);

        try
        {
            while (!ct.IsCancellationRequested)
            {
                var result = consumer.Consume(TimeSpan.FromMilliseconds(100));
                if (result != null)
                {
                    yield return new KafkaMessage(
                        result.Topic,
                        result.Partition.Value,
                        result.Offset.Value,
                        result.Message.Key,
                        result.Message.Value,
                        result.Message.Timestamp.UtcDateTime);
                }
            }
        }
        finally
        {
            consumer.Unsubscribe();
            _logger.LogInformation("Stopped streaming messages from topic {Topic}", topic);
        }
    }

    private IEnumerable<int> GetTopicPartitions(string topic)
    {
        using var adminClient = new AdminClientBuilder(new AdminClientConfig
        {
            BootstrapServers = _bootstrapServers
        }).Build();

        var metadata = adminClient.GetMetadata(topic, TimeSpan.FromSeconds(5));
        var topicMeta = metadata.Topics.FirstOrDefault(t => t.Topic == topic);

        return topicMeta?.Partitions.Select(p => p.PartitionId) ?? Enumerable.Empty<int>();
    }
}
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds without errors
  </verify>
  <done>
KafkaConsumerService can read recent messages and stream live messages from topics
  </done>
</task>

<task type="auto">
  <name>Task 2: Create KafkaController REST API</name>
  <files>src/FileSimulator.ControlApi/Controllers/KafkaController.cs</files>
  <action>
Create REST API controller following existing MetricsController pattern.

```csharp
using Microsoft.AspNetCore.Mvc;
using FileSimulator.ControlApi.Models;
using FileSimulator.ControlApi.Services;

namespace FileSimulator.ControlApi.Controllers;

[ApiController]
[Route("api/kafka")]
public class KafkaController : ControllerBase
{
    private readonly IKafkaAdminService _adminService;
    private readonly IKafkaProducerService _producerService;
    private readonly IKafkaConsumerService _consumerService;
    private readonly ILogger<KafkaController> _logger;

    public KafkaController(
        IKafkaAdminService adminService,
        IKafkaProducerService producerService,
        IKafkaConsumerService consumerService,
        ILogger<KafkaController> logger)
    {
        _adminService = adminService;
        _producerService = producerService;
        _consumerService = consumerService;
        _logger = logger;
    }

    // ===== Topics =====

    /// <summary>List all topics</summary>
    [HttpGet("topics")]
    public async Task<ActionResult<IReadOnlyList<TopicInfo>>> GetTopics(CancellationToken ct)
    {
        var topics = await _adminService.GetTopicsAsync(ct);
        return Ok(topics);
    }

    /// <summary>Get specific topic</summary>
    [HttpGet("topics/{name}")]
    public async Task<ActionResult<TopicInfo>> GetTopic(string name, CancellationToken ct)
    {
        var topic = await _adminService.GetTopicAsync(name, ct);
        if (topic == null)
            return NotFound($"Topic '{name}' not found");
        return Ok(topic);
    }

    /// <summary>Create a new topic</summary>
    [HttpPost("topics")]
    public async Task<ActionResult<TopicInfo>> CreateTopic(
        [FromBody] CreateTopicRequest request,
        CancellationToken ct)
    {
        try
        {
            await _adminService.CreateTopicAsync(request, ct);
            var topic = await _adminService.GetTopicAsync(request.Name, ct);
            return CreatedAtAction(nameof(GetTopic), new { name = request.Name }, topic);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to create topic {Name}", request.Name);
            return BadRequest(new { error = ex.Message });
        }
    }

    /// <summary>Delete a topic</summary>
    [HttpDelete("topics/{name}")]
    public async Task<IActionResult> DeleteTopic(string name, CancellationToken ct)
    {
        try
        {
            await _adminService.DeleteTopicAsync(name, ct);
            return NoContent();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to delete topic {Name}", name);
            return BadRequest(new { error = ex.Message });
        }
    }

    // ===== Messages =====

    /// <summary>Get recent messages from topic</summary>
    [HttpGet("topics/{name}/messages")]
    public async Task<ActionResult<IReadOnlyList<KafkaMessage>>> GetMessages(
        string name,
        [FromQuery] int count = 50,
        CancellationToken ct = default)
    {
        try
        {
            var messages = await _consumerService.GetRecentMessagesAsync(name, count, ct);
            return Ok(messages);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to get messages from topic {Name}", name);
            return BadRequest(new { error = ex.Message });
        }
    }

    /// <summary>Produce a message to a topic</summary>
    [HttpPost("topics/{name}/messages")]
    public async Task<ActionResult<ProduceMessageResult>> ProduceMessage(
        string name,
        [FromBody] ProduceMessageRequest request,
        CancellationToken ct)
    {
        try
        {
            // Ensure topic name matches route
            var actualRequest = request with { Topic = name };
            var result = await _producerService.ProduceAsync(actualRequest, ct);
            return Ok(result);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to produce message to topic {Name}", name);
            return BadRequest(new { error = ex.Message });
        }
    }

    // ===== Consumer Groups =====

    /// <summary>List all consumer groups</summary>
    [HttpGet("consumer-groups")]
    public async Task<ActionResult<IReadOnlyList<ConsumerGroupInfo>>> GetConsumerGroups(CancellationToken ct)
    {
        var groups = await _adminService.GetConsumerGroupsAsync(ct);
        return Ok(groups);
    }

    /// <summary>Get consumer group details</summary>
    [HttpGet("consumer-groups/{groupId}")]
    public async Task<ActionResult<ConsumerGroupDetail>> GetConsumerGroup(string groupId, CancellationToken ct)
    {
        var group = await _adminService.GetConsumerGroupDetailAsync(groupId, ct);
        if (group == null)
            return NotFound($"Consumer group '{groupId}' not found");
        return Ok(group);
    }

    /// <summary>Reset consumer group offsets</summary>
    [HttpPost("consumer-groups/{groupId}/reset")]
    public async Task<IActionResult> ResetOffsets(
        string groupId,
        [FromBody] ResetOffsetsRequest request,
        CancellationToken ct)
    {
        try
        {
            var actualRequest = request with { GroupId = groupId };
            await _adminService.ResetOffsetsAsync(actualRequest, ct);
            return Ok(new { message = $"Offsets reset for group '{groupId}'" });
        }
        catch (InvalidOperationException ex)
        {
            return BadRequest(new { error = ex.Message });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to reset offsets for group {GroupId}", groupId);
            return BadRequest(new { error = ex.Message });
        }
    }

    /// <summary>Delete a consumer group</summary>
    [HttpDelete("consumer-groups/{groupId}")]
    public async Task<IActionResult> DeleteConsumerGroup(string groupId, CancellationToken ct)
    {
        try
        {
            await _adminService.DeleteConsumerGroupAsync(groupId, ct);
            return NoContent();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to delete consumer group {GroupId}", groupId);
            return BadRequest(new { error = ex.Message });
        }
    }

    // ===== Health =====

    /// <summary>Check Kafka connectivity</summary>
    [HttpGet("health")]
    public async Task<ActionResult> HealthCheck(CancellationToken ct)
    {
        var healthy = await _adminService.HealthCheckAsync(ct);
        if (healthy)
            return Ok(new { status = "healthy" });
        return ServiceUnavailable(new { status = "unhealthy" });
    }

    private ObjectResult ServiceUnavailable(object value)
    {
        return StatusCode(503, value);
    }
}
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds without errors
  </verify>
  <done>
KafkaController exposes all Kafka operations via REST API with proper HTTP verbs and status codes
  </done>
</task>

<task type="auto">
  <name>Task 3: Create KafkaHub and register services in Program.cs</name>
  <files>
src/FileSimulator.ControlApi/Hubs/KafkaHub.cs
src/FileSimulator.ControlApi/Program.cs
  </files>
  <action>
**Create KafkaHub.cs:**

```csharp
using Microsoft.AspNetCore.SignalR;
using FileSimulator.ControlApi.Models;
using FileSimulator.ControlApi.Services;

namespace FileSimulator.ControlApi.Hubs;

/// <summary>
/// SignalR hub for real-time Kafka message streaming.
/// Clients can subscribe to topics and receive messages as they arrive.
/// </summary>
public class KafkaHub : Hub
{
    private readonly IKafkaConsumerService _consumerService;
    private readonly ILogger<KafkaHub> _logger;

    public KafkaHub(IKafkaConsumerService consumerService, ILogger<KafkaHub> logger)
    {
        _consumerService = consumerService;
        _logger = logger;
    }

    /// <summary>
    /// Subscribe to receive messages from a topic.
    /// Messages will be pushed via "KafkaMessage" event.
    /// </summary>
    public async Task SubscribeToTopic(string topic)
    {
        await Groups.AddToGroupAsync(Context.ConnectionId, $"topic:{topic}");
        _logger.LogInformation("Client {ConnectionId} subscribed to topic {Topic}",
            Context.ConnectionId, topic);

        // Start streaming in background
        _ = StreamMessagesAsync(topic, Context.ConnectionAborted);
    }

    /// <summary>
    /// Unsubscribe from a topic.
    /// </summary>
    public async Task UnsubscribeFromTopic(string topic)
    {
        await Groups.RemoveFromGroupAsync(Context.ConnectionId, $"topic:{topic}");
        _logger.LogInformation("Client {ConnectionId} unsubscribed from topic {Topic}",
            Context.ConnectionId, topic);
    }

    private async Task StreamMessagesAsync(string topic, CancellationToken ct)
    {
        try
        {
            await foreach (var message in _consumerService.StreamMessagesAsync(topic, ct))
            {
                await Clients.Group($"topic:{topic}").SendAsync("KafkaMessage", message, ct);
            }
        }
        catch (OperationCanceledException)
        {
            // Client disconnected, normal termination
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error streaming messages from topic {Topic}", topic);
        }
    }

    public override async Task OnConnectedAsync()
    {
        _logger.LogInformation("Client connected to KafkaHub: {ConnectionId}", Context.ConnectionId);
        await base.OnConnectedAsync();
    }

    public override async Task OnDisconnectedAsync(Exception? exception)
    {
        if (exception != null)
        {
            _logger.LogWarning(exception, "Client disconnected from KafkaHub with error: {ConnectionId}",
                Context.ConnectionId);
        }
        else
        {
            _logger.LogInformation("Client disconnected from KafkaHub: {ConnectionId}", Context.ConnectionId);
        }
        await base.OnDisconnectedAsync(exception);
    }
}
```

**Update Program.cs:**

1. Add KafkaOptions configuration:
```csharp
builder.Services.Configure<KafkaOptions>(
    builder.Configuration.GetSection("Kafka"));
```

2. Register Kafka services (add after existing service registrations):
```csharp
// Kafka services
builder.Services.AddSingleton<IKafkaAdminService, KafkaAdminService>();
builder.Services.AddSingleton<IKafkaProducerService, KafkaProducerService>();
builder.Services.AddSingleton<IKafkaConsumerService, KafkaConsumerService>();
```

3. Map KafkaHub (add after existing MapHub calls):
```csharp
app.MapHub<KafkaHub>("/hubs/kafka");
```

4. Update API root endpoint to include Kafka endpoints:
```csharp
endpoints = new[]
{
    // ... existing endpoints ...
    "/api/kafka/topics",
    "/api/kafka/consumer-groups",
    "/api/kafka/health",
    "/hubs/kafka"
}
```

5. Add startup log:
```csharp
Log.Information("Kafka hub available at /hubs/kafka");
```
  </action>
  <verify>
`dotnet build src/FileSimulator.ControlApi` succeeds and Program.cs includes all Kafka registrations
  </verify>
  <done>
KafkaHub enables real-time message streaming, all services registered in DI, endpoints documented
  </done>
</task>

</tasks>

<verification>
1. `dotnet build src/FileSimulator.ControlApi` - builds without errors
2. KafkaController has all required endpoints (topics CRUD, messages, consumer groups)
3. KafkaHub registered at /hubs/kafka
4. All Kafka services registered in DI as singletons
5. API root lists new Kafka endpoints
</verification>

<success_criteria>
- REST API endpoints cover all Kafka operations
- SignalR hub enables real-time message streaming
- Services properly registered with DI
- Error handling returns appropriate HTTP status codes
- Logging added for debugging
</success_criteria>

<output>
After completion, create `.planning/phases/10-kafka-integration/10-03-SUMMARY.md`
</output>
