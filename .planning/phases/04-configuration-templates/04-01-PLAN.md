---
phase: 04-configuration-templates
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - helm-chart/file-simulator/examples/pv/nas-input-1-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-input-2-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-input-3-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-backup-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-output-1-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-output-2-pv.yaml
  - helm-chart/file-simulator/examples/pv/nas-output-3-pv.yaml
  - helm-chart/file-simulator/examples/pvc/nas-input-1-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-input-2-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-input-3-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-backup-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-output-1-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-output-2-pvc.yaml
  - helm-chart/file-simulator/examples/pvc/nas-output-3-pvc.yaml
autonomous: true

must_haves:
  truths:
    - "7 PersistentVolume YAML files exist with correct NFS server addresses"
    - "7 PersistentVolumeClaim YAML files exist with label selectors matching PVs"
    - "PV/PVC configuration matches production OCP patterns (static provisioning)"
    - "Each PV points to unique NAS service DNS name"
  artifacts:
    - path: "helm-chart/file-simulator/examples/pv/nas-input-1-pv.yaml"
      provides: "PV for nas-input-1 with NFS server DNS"
      contains: "file-sim-nas-input-1.file-simulator.svc.cluster.local"
    - path: "helm-chart/file-simulator/examples/pvc/nas-input-1-pvc.yaml"
      provides: "PVC binding to nas-input-1-pv via selector"
      contains: "nas-server: nas-input-1"
  key_links:
    - from: "pvc/nas-input-1-pvc.yaml"
      to: "pv/nas-input-1-pv.yaml"
      via: "selector.matchLabels.nas-server"
      pattern: "nas-server: nas-input-1"
---

<objective>
Create static PersistentVolume and PersistentVolumeClaim YAML manifests for all 7 NAS servers

Purpose: Enable developers to mount NAS servers using production-identical Kubernetes patterns. Static PV/PVC provisioning matches how production OCP environments configure pre-existing NAS storage.

Output: 14 YAML files (7 PVs + 7 PVCs) in helm-chart/file-simulator/examples/ directory
</objective>

<execution_context>
@C:\Users\UserC\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\UserC\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-configuration-templates/04-RESEARCH.md
@helm-chart/file-simulator/values-multi-nas.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create 7 PersistentVolume YAML files</name>
  <files>
    helm-chart/file-simulator/examples/pv/nas-input-1-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-input-2-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-input-3-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-backup-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-output-1-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-output-2-pv.yaml
    helm-chart/file-simulator/examples/pv/nas-output-3-pv.yaml
  </files>
  <action>
Create 7 PersistentVolume YAML files following the pattern from 04-RESEARCH.md.

Each PV must include:
- apiVersion: v1
- kind: PersistentVolume
- metadata.name: {nas-name}-pv (e.g., nas-input-1-pv)
- metadata.labels:
  - type: nfs
  - nas-role: input|backup|output (based on server type)
  - nas-server: {nas-name}
  - environment: development
- spec.capacity.storage: 10Gi
- spec.accessModes: [ReadWriteMany]
- spec.persistentVolumeReclaimPolicy: Retain
- spec.nfs.server: file-sim-nas-{name}.file-simulator.svc.cluster.local
- spec.nfs.path: /data
- spec.mountOptions: [nfsvers=3, tcp, hard, intr]

Server mapping (from values-multi-nas.yaml):
- nas-input-1: role=input, service=file-sim-nas-input-1
- nas-input-2: role=input, service=file-sim-nas-input-2
- nas-input-3: role=input, service=file-sim-nas-input-3
- nas-backup: role=backup, service=file-sim-nas-backup
- nas-output-1: role=output, service=file-sim-nas-output-1
- nas-output-2: role=output, service=file-sim-nas-output-2
- nas-output-3: role=output, service=file-sim-nas-output-3

Include comment header in each file explaining purpose and linking to integration guide.
  </action>
  <verify>
Verify all 7 PV files exist:
```bash
ls helm-chart/file-simulator/examples/pv/*.yaml | wc -l
# Expected: 7
```

Verify each PV has correct NFS server DNS:
```bash
grep -h "server:" helm-chart/file-simulator/examples/pv/*.yaml
# Expected: 7 unique DNS names
```

Verify labels exist:
```bash
grep -c "nas-server:" helm-chart/file-simulator/examples/pv/*.yaml
# Expected: 7 files with 1 match each
```
  </verify>
  <done>
7 PV YAML files exist in helm-chart/file-simulator/examples/pv/ with correct NFS server DNS names, labels, and mount options matching production OCP patterns
  </done>
</task>

<task type="auto">
  <name>Task 2: Create 7 PersistentVolumeClaim YAML files</name>
  <files>
    helm-chart/file-simulator/examples/pvc/nas-input-1-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-input-2-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-input-3-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-backup-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-output-1-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-output-2-pvc.yaml
    helm-chart/file-simulator/examples/pvc/nas-output-3-pvc.yaml
  </files>
  <action>
Create 7 PersistentVolumeClaim YAML files following the pattern from 04-RESEARCH.md.

Each PVC must include:
- apiVersion: v1
- kind: PersistentVolumeClaim
- metadata.name: {nas-name}-pvc (e.g., nas-input-1-pvc)
- metadata.namespace: default (users change for their namespace)
- metadata.labels:
  - nas-server: {nas-name}
  - nas-role: input|backup|output
- spec.accessModes: [ReadWriteMany]
- spec.resources.requests.storage: 10Gi
- spec.selector.matchLabels.nas-server: {nas-name}

CRITICAL: Do NOT include storageClassName. Omitting it enables static PV binding via selector.

PVC to PV mapping (same names, different suffixes):
- nas-input-1-pvc -> nas-input-1-pv (via selector nas-server: nas-input-1)
- nas-input-2-pvc -> nas-input-2-pv (via selector nas-server: nas-input-2)
- etc.

Include comment header in each file explaining:
1. Purpose of this PVC
2. Which PV it binds to
3. How to deploy to different namespace
  </action>
  <verify>
Verify all 7 PVC files exist:
```bash
ls helm-chart/file-simulator/examples/pvc/*.yaml | wc -l
# Expected: 7
```

Verify each PVC has selector matching PV:
```bash
grep -h "nas-server:" helm-chart/file-simulator/examples/pvc/*.yaml | grep -c "nas-"
# Expected: 14 (7 files x 2 occurrences: labels + selector)
```

Verify no storageClassName (would break static binding):
```bash
grep -c "storageClassName" helm-chart/file-simulator/examples/pvc/*.yaml
# Expected: 0
```
  </verify>
  <done>
7 PVC YAML files exist in helm-chart/file-simulator/examples/pvc/ with correct selectors binding to corresponding PVs, no storageClassName
  </done>
</task>

<task type="auto">
  <name>Task 3: Validate PV/PVC manifest correctness</name>
  <files>None (validation only)</files>
  <action>
Validate all 14 manifests are syntactically correct and follow Kubernetes patterns.

Validation checks:
1. kubectl --dry-run=client validation for all PV files
2. kubectl --dry-run=client validation for all PVC files
3. Verify PV-PVC label selector alignment (each PVC's selector matches exactly one PV's labels)
4. Verify NFS paths all point to /data (unfs3 export path)
5. Verify all PVs have Retain reclaim policy (prevents data loss)

Run validation:
```bash
# Validate all PV manifests
for f in helm-chart/file-simulator/examples/pv/*.yaml; do
  kubectl apply --dry-run=client -f "$f" 2>&1
done

# Validate all PVC manifests
for f in helm-chart/file-simulator/examples/pvc/*.yaml; do
  kubectl apply --dry-run=client -f "$f" 2>&1
done
```

If any validation fails, fix the manifest before proceeding.
  </action>
  <verify>
All manifests pass kubectl dry-run validation:
```bash
kubectl apply --dry-run=client -f helm-chart/file-simulator/examples/pv/ 2>&1 | grep -c "created"
# Expected: 7

kubectl apply --dry-run=client -f helm-chart/file-simulator/examples/pvc/ 2>&1 | grep -c "created"
# Expected: 7
```
  </verify>
  <done>
All 14 PV/PVC manifests pass kubectl dry-run validation with no errors
  </done>
</task>

</tasks>

<verification>
## Overall Verification

1. Directory structure exists:
   - helm-chart/file-simulator/examples/pv/ (7 files)
   - helm-chart/file-simulator/examples/pvc/ (7 files)

2. All files syntactically valid (kubectl dry-run passes)

3. PV requirements met:
   - Each has unique NFS server DNS name
   - All use ReadWriteMany access mode
   - All use Retain reclaim policy
   - All mount /data with nfsvers=3 options

4. PVC requirements met:
   - Each has selector matching exactly one PV
   - No storageClassName (static binding)
   - Namespace set to default (customizable)
</verification>

<success_criteria>
- [ ] 7 PV YAML files created with correct NFS server DNS names
- [ ] 7 PVC YAML files created with matching label selectors
- [ ] All 14 manifests pass kubectl --dry-run=client validation
- [ ] PVs use Retain reclaim policy (no data loss on PVC delete)
- [ ] PVCs have no storageClassName (enables static binding)
- [ ] Each PV/PVC pair has consistent naming: {nas-name}-pv / {nas-name}-pvc
</success_criteria>

<output>
After completion, create `.planning/phases/04-configuration-templates/04-01-SUMMARY.md`
</output>
